{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a02e21-1d30-4ee1-ac10-d4837bf2c8fc",
   "metadata": {},
   "source": [
    "## Making Decisions with Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72064a2f-e4a9-487d-932d-9bd61df781ea",
   "metadata": {},
   "source": [
    "### Using existinging packages to make things easier!\n",
    "\n",
    "Last week we wrote our own functions to calculate average and standard deviation. We won't have to do that every time; those functions are actually built into a number of other python packages. In this case, we're using mean from a package called numpy, and standard deviation from a package called scipy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95140d83-9005-4dc0-81b4-a8ee22262a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "data1 = [14.1, 11.0, 13.8, 13.6, 14.8] #ppb\n",
    "x_Pb = np.mean(data1)\n",
    "s_Pb = stats.tstd(data1)\n",
    "\n",
    "# fancy F printing for fancy output statements\n",
    "\n",
    "print(F'The average lead measurement is {x_Pb} +/- {s_Pb} ug/L')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa8de6-9008-4e41-9fd9-02f03bdd9832",
   "metadata": {},
   "source": [
    "## Correctly Formatting Outputs\n",
    "\n",
    "\n",
    "<b> Whoa, thats a lot of digits! </b> That can't possibly be the right number of significant digits, right? Remember that the computer only knows how to do what you tell it to do! So if you don't tell it to round to a certain number of digits, it will just give you everything it has stored. So lets figure out how to round those numbers to something a little more reasonable, and while we're at it, we'll do a better job of presenting this data with the correct formatting of average +/- standard deviation.\n",
    "\n",
    "### New Rule for Sig Figs\n",
    "\n",
    "Forget the rules you memorized in gen chem for significant figures. When working with real data, we should always have a reasonable approximation of error, which will define our significant digits for us. In this case, we'll use standard deviation as our estimate of error. So you have two steps now to determine correct significant figures:\n",
    "1. Round the error value to one significant digit (or two IF the error value begins with a 1)\n",
    "2. Round the average to the same decimal place as the error value\n",
    "\n",
    "### Formatting Results\n",
    "Never report averages without error, and never report averages or errors without units! The correct format, if we're working with absolte error, is always \"average +/- error units\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ebd470-ca67-4aeb-9714-e42dd6e91987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using F printing to get the correct sig figs and formatting for this answer\n",
    "\n",
    "print(F'The average lead measurement in our data set is {x_Pb:.4f} +/- {s_Pb:.4f} ppb')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1507e4-79ad-48cf-92f9-ef8d038e27c0",
   "metadata": {},
   "source": [
    "## Part 6 - Confidence Intervals\n",
    "\n",
    "So far, everything we've done should have been a review from Gen Chem! But we can do better than standard deviation as an estimate of error for experimental data. To do this, we use Confidence Intervals\n",
    "\n",
    "The equation for confidence interval is  $$ CI= {\\frac {ts}{\\sqrt {n}}} $$ We already know how to get n (from the length of the list!) and you already calculated s! So now we just need t. Luckily, Python has those t-tables from your text book ( ), we just have to tell it which one we need! See the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbda739-01b3-40c5-a9fb-9eae37580945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import math\n",
    "#the first input is confidence %, the second is degrees of freedom (n-1)\n",
    "\n",
    "# we will always use \"two tailed t values\", so the confidence interval format is slightly different than expected\n",
    "\n",
    "#confidence level\n",
    "\n",
    "alpha =  # 1- alpha should equal your confidence interval, as a decimal. So for example, alpha is 0.05 for a 95% confidence interval\n",
    "dof =  # degrees of freedom is the number of samples (i.e. the length of the list) minus one\n",
    "\n",
    "#two tailed t statistics require the following format:\n",
    "\n",
    "t = stats.t.ppf(1-alpha/2, dof) #inputs are alpha to set the confidence interval and degrees of freedom\n",
    "\n",
    "#check that this matches the value in the textbook!\n",
    "print(t)\n",
    "\n",
    "\n",
    "# calculate the actual confidence interval\n",
    "CI = s_Pb*t/math.sqrt(len(data1))\n",
    "\n",
    "\n",
    "print (F\"the average concentration is {x_Pb:.1f} +/- {CI:.1f} ppb\")\n",
    "print(F\"the range of possible values that we expect to measure for this sample (95 times out of 100) would be as low as {x_Pb-CI} or as high as {x_Pb+CI} ppb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b60a8f-c4b9-413f-b2c1-ee21969a2959",
   "metadata": {},
   "source": [
    "## The Grubbs test or how to discard outliers\n",
    "Now you have the average and the standard deviation of your data. Do you think there might be any outliers? Any values which seem really far away from your mean, and which you think might be the result of a systemattic error (the empty flask was still wet) or a mistake, rather than just random variation?\n",
    "\n",
    "We can't just go throwing data points out  because we think they look funky. But we can try a statistic test to see how likely it is that the data point we're suspicious about came from our data set. This test is a called a <b> Grubb's test </b>\n",
    "\n",
    "First, we must calculate a G value for our data, using our average ($ {\\bar  {x}} $ ), our standard deviation (s) and our most likely ourlier ( $ x_{i} $ ). We will plug those values into the following equation: $ G={\\frac {\\left\\vert x_{i}-{\\bar  {x}}\\right\\vert }{s}} $\n",
    "\n",
    "We then must compare our G value to a 'G critical' value, which we must look up in a table. Our null hypothesis is that our calculated G value will be less than the 'G critical' value, and that our value is NOT an outlier. Only if our calculated G value is greater than a G critical value, can we discard that value as an outlier.\n",
    "\n",
    "<b> Before you continue, answer the following questions </b>\n",
    "1. Look at the lead measurements from week 1 and pick a likely outlier. Explain why you think it is possibly an outlier.\n",
    "\n",
    "2. Calculate G for your suspected outlier. \n",
    "\n",
    "3. Look up G critical ([Appendix 7 in our text](https://chem.libretexts.org/Bookshelves/Analytical_Chemistry/Analytical_Chemistry_2.1_(Harvey)/16%3A_Appendix/16.07%3A_Critical_Values_for_Grubb's_Test)), and compare it to your calculated G. Is this value an outlier, or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e2b4b-ed24-4e24-a397-1ef2f809271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python doesn't happen to have an easy look-up for the Grubb's critical values, \n",
    "# so just enter the one you looked up in the textbook and complete the the next line:\n",
    "G_crit = \n",
    "# Note: This G_crit value is for ? observations and ? confidence level.\n",
    "\n",
    "# enter your suspect value here (where is it in your data array?)\n",
    "suspect = data[]\n",
    "\n",
    "# Note: The function abs() calculates the absolute value by changing negative numbers to positive.\n",
    "G_calc = abs(suspect - average)/std\n",
    "\n",
    "if G_calc < G_crit:\n",
    "    print (F'{G_calc} is less than {G_crit} and so {suspect} is not an outlier')\n",
    "    \n",
    "if G_calc > G_crit:\n",
    "    print (F'{G_calc} is greater than {G_crit} and so {suspect} is an outlier and should be removed from the data.')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c50ba2-d5b5-4038-992e-68e1025bb5cb",
   "metadata": {},
   "source": [
    "## T test - Compare to a given value\n",
    "\n",
    "In this case, we're most interested in whether we think it's reasonable that the actual sample value might be 15 ppb. That is the legal limit for lead in water, and so if it's possible that this sample equals (or exceeds) 15 ppb, we have a serious problem, but our water company also has a legal obligation to act! So, when does 13 = 15?\n",
    "\n",
    "In this case, our null hypothesis is that our average = given value (ie. $ {\\bar  {x} = {\\mu}} $); in this case, that our average, 13.5 ppb = 15 ppb.\n",
    "\n",
    "In order to reject that hypothesis, our t_calcuated needs to be bigger than t_critical for this sample.\n",
    "$$ t_\\text{calculated} = \\frac {|\\mu - \\overline{X}| \\sqrt{n}} {s} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56349d-8801-4590-822e-654496d27073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to look up t_table\n",
    "\n",
    "alpha = 0.05 # 1- alpha should equal your confidence interval. Here, we use 0.05, for a 95% confidence interval\n",
    "dof = len(data1) - 1 # degrees of freedom is the number of samples (i.e. the length of the list) minus one\n",
    "n = len(data1)\n",
    "#two tailed t statistics require the following format:\n",
    "\n",
    "t_table = stats.t.ppf(1-alpha/2, dof) #inputs are alpha to set the confidence interval and degrees of freedom\n",
    "\n",
    "# then we need to calculate t_calculated\n",
    "\n",
    "mu = 15  # the value we're testing against\n",
    "\n",
    "t_calc = (abs( mu - x_Pb)*math.sqrt(n))/(s_Pb)\n",
    "\n",
    "# Let's think about how to set this up as an if statement\n",
    "\n",
    "if t_calc > t_table:\n",
    "    #what will be true?\n",
    "    print(F\"something\")\n",
    "    \n",
    "if t_calc <= t_table:\n",
    "    print(F\"something else\")\n",
    "    #what will be true?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef63a85d-2830-4540-9685-fb3f2de7ab02",
   "metadata": {},
   "source": [
    "## F test - Compare Variance\n",
    "\n",
    "The F test compares variance, or standard deviations, to determine whether they are similar. This can help us understand whether the precision of two measurement methods is similar, but mainly it's useful for choosing which t-test we want to use when comparing multiple data sets.\n",
    "\n",
    "The F critical values have to be looked up, just like t and Grubb's critical values. Luckily, Python also has a function for F values. \n",
    "The F calculated (or F expeirmental) value is caclulated as $ F = \\frac {s_1}{s_2} $ where s1 is the larger of the two standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6218c07-9f67-4c0f-b9d2-57c9d3e3f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like t values, we can tell python to look up critical F values for us as well!\n",
    "# Now, we can get an F critical value. What are each of those values in that equation? Double check that \n",
    "# they are right for our equation, and add comments to explain!\n",
    "\n",
    "data2 = [13.56, 14.01, 13.98, 13.45, 14.12] #ppb\n",
    "\n",
    "# add mean, std and n for data2\n",
    "\n",
    "\n",
    "#F critical lookup code: stats.f.ppf(confidence level, n dataset 1, n dataset 2)\n",
    "\n",
    "F_crit = stats.f.ppf(q=1-0.05, dfn=, dfd=)\n",
    "\n",
    "print (F_crit)\n",
    "\n",
    "F_calc = # what goes here?\n",
    "\n",
    "# Here, add equations for the correct t test and the correct degrees of freedom calculations\n",
    "# Note that there must be a colon at the end of the if statement!\n",
    "\n",
    "if F_calc < F_crit:\n",
    "    print (\"Something\")\n",
    "    \n",
    "#\n",
    "if F_calc >= F_crit:\n",
    "    print (\"Something else?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1bc345-a0e7-4831-b6af-a16a7f463936",
   "metadata": {},
   "source": [
    "## T - test to compare two means\n",
    "\n",
    "Once you know whether the standard devations are statistically different, you can choose your t test. Note that each t-test has a <b> different </b> equation for t_calculated AND a different equation for degrees of freedom! We'll take advantage of the F test results to make additional decisions here.\n",
    "\n",
    "T-test option 2A (Samples have equal variance)\n",
    "\n",
    "$$ t_\\text{exp} = \\frac {|\\overline{X}_A - \\overline{X}_B|} {s_\\text{pool}} \\times \\sqrt{\\frac {n_A n_B} {n_A + n_B}} $$\n",
    "\n",
    "$$ s_\\text{pool} = \\sqrt{\\frac {(n_A - 1) s_A^2 + (n_B - 1)s_B^2} {n_A + n_B - 2}} $$ \n",
    "\n",
    "$$ d.o.f = n1 + n2 -2 $$\n",
    "\n",
    "\n",
    "T-test option 2B (Samples do not have equal variance)\n",
    "\n",
    "$$ t_\\text{exp} = \\frac {|\\overline{X}_A - \\overline{X}_B|} {\\sqrt{\\frac {s_A^2} {n_A} + \\frac {s_B^2} {n_B}}} $$\n",
    "\n",
    "$$ d.o.f = \\frac {\\left( \\frac {s_A^2} {n_A} + \\frac {s_B^2} {n_B} \\right)^2} {\\frac {\\left( \\frac {s_A^2} {n_A} \\right)^2} {n_A + 1} + \\frac {\\left( \\frac {s_B^2} {n_B} \\right)^2} {n_B + 1}} - 2  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff513a7e-7d8f-43a8-bba4-69c6e9c62266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add t and dof calculations to your F tests!\n",
    "\n",
    "\n",
    "# then, add if statements here to make your final decision!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
